{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Hands-on Lab : Web Scraping**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30 to 45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will perform the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Extract information from a given web site \n",
    "* Write the scraped data into a csv file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract information from the given web site\n",
    "You will extract the data from the below web site: <br> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this url contains the data you need to scrape\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data you need to scrape is the **name of the programming language** and **average annual salary**.<br> It is a good idea to open the url in your web broswer and study the contents of the web page before you start to scrape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (2.29.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (4.11.1)\n",
      "Requirement already satisfied: pandas in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (2023.5.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# 1. For downloading the webpage\n",
    "import requests\n",
    "\n",
    "# 2. For parsing and extracting data from HTML\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Optional but very helpful:\n",
    "import pandas as pd  # For organizing data into tables and saving to CSV/Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the webpage at the url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Downloading webpage from: https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\n",
      "‚úÖ Successfully downloaded webpage!\n",
      "üìÑ Content length: 2,170 characters\n",
      "üìÑ Content type: text/html\n",
      "\n",
      "üîç PREVIEW (first 500 characters):\n",
      "============================================================\n",
      "<!doctype html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "<title>\n",
      "Salary survey results of programming languages\n",
      "</title>\n",
      "<style>\n",
      "table, th, td {\n",
      "  border: 1px solid black;\n",
      "}\n",
      "</style>\n",
      "</head>\n",
      "\n",
      "<body>\n",
      "<hr />\n",
      "<h2>Popular Programming Languages</h2>\n",
      "<hr />\n",
      "<p>Finding out which is the best language is a tough task. A programming language is created to solve a specific problem. A language which is good for task A may not be able to properly handle task B. Comparing programming language is never easy. What we can do, ho\n",
      "============================================================\n",
      "\n",
      "üíæ Saved as: Programming_Languages.html\n",
      "‚úÖ Created BeautifulSoup object for parsing\n",
      "\n",
      "üìä PAGE STRUCTURE:\n",
      "   Title: \n",
      "Salary survey results of programming languages\n",
      "\n",
      "   Number of tables: 1\n",
      "   Contains programming language data: ‚úì\n"
     ]
    }
   ],
   "source": [
    "#your code goes here\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# The URL containing programming languages data\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\"\n",
    "\n",
    "print(f\"üì• Downloading webpage from: {url}\")\n",
    "\n",
    "# DOWNLOAD THE WEBPAGE\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if download was successful\n",
    "if response.status_code == 200:\n",
    "    print(f\"‚úÖ Successfully downloaded webpage!\")\n",
    "    print(f\"üìÑ Content length: {len(response.text):,} characters\")\n",
    "    print(f\"üìÑ Content type: {response.headers.get('content-type', 'Unknown')}\")\n",
    "    \n",
    "    # Let's see a preview of what we downloaded\n",
    "    print(f\"\\nüîç PREVIEW (first 500 characters):\")\n",
    "    print(\"=\"*60)\n",
    "    print(response.text[:500])\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Save the webpage to a file for inspection\n",
    "    with open(\"Programming_Languages.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(response.text)\n",
    "    print(f\"\\nüíæ Saved as: Programming_Languages.html\")\n",
    "    \n",
    "    # Create BeautifulSoup object for parsing\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    print(f\"‚úÖ Created BeautifulSoup object for parsing\")\n",
    "    \n",
    "    # Quick analysis of what's in the page\n",
    "    print(f\"\\nüìä PAGE STRUCTURE:\")\n",
    "    print(f\"   Title: {soup.title.string if soup.title else 'No title found'}\")\n",
    "    \n",
    "    # Check for tables (likely where our data is)\n",
    "    tables = soup.find_all('table')\n",
    "    print(f\"   Number of tables: {len(tables)}\")\n",
    "    \n",
    "    # Check for programming language keywords\n",
    "    if 'python' in response.text.lower() or 'java' in response.text.lower():\n",
    "        print(f\"   Contains programming language data: ‚úì\")\n",
    "        \n",
    "else:\n",
    "    print(f\"‚ùå Failed to download webpage. Status code: {response.status_code}\")\n",
    "    print(f\"Error: {response.text[:200] if response.text else 'No error message'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a soup object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê Downloading from: https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\n",
      "‚úÖ Downloaded 2,170 characters\n",
      "\n",
      "‚úÖ CREATED BeautifulSoup OBJECT!\n",
      "   Type: <class 'bs4.BeautifulSoup'>\n",
      "   Parser used: html.parser\n",
      "\n",
      "üîç TESTING SOUP OBJECT:\n",
      "   1. Page title: \n",
      "Salary survey results of programming languages\n",
      "\n",
      "   2. Element counts:\n",
      "      ‚Ä¢ <table> tags: 1\n",
      "      ‚Ä¢ <tr> tags (table rows): 11\n",
      "      ‚Ä¢ <td> tags (table cells): 55\n",
      "\n",
      "üîé LOOKING FOR PROGRAMMING LANGUAGE DATA:\n",
      "   Found references to: Python, Java, C++, C#, PHP, SQL, Swift, Go\n",
      "\n",
      "üìù PARSED HTML SAMPLE (first 300 characters of prettified version):\n",
      "============================================================\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <title>\n",
      "   Salary survey results of programming languages\n",
      "  </title>\n",
      "  <style>\n",
      "   table, th, td {\n",
      "  border: 1px solid black;\n",
      "}\n",
      "  </style>\n",
      " </head>\n",
      " <body>\n",
      "  <hr/>\n",
      "  <h2>\n",
      "   Popular Programming Languages\n",
      "  </h2>\n",
      "  <hr/>\n",
      "  <p>\n",
      "   Finding out which is the best\n",
      "============================================================\n",
      "\n",
      "‚ú® Soup object is ready! You can now use it to:\n",
      "   ‚Ä¢ Find tables: soup.find_all('table')\n",
      "   ‚Ä¢ Extract data: soup.find_all('tr')\n",
      "   ‚Ä¢ Search for text: soup.find_all(text='Python')\n"
     ]
    }
   ],
   "source": [
    "#your code goes here\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# The URL containing programming languages data\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\"\n",
    "\n",
    "print(f\"üåê Downloading from: {url}\")\n",
    "\n",
    "# 1. Download the webpage\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code != 200:\n",
    "    print(f\"‚ùå Download failed. Status: {response.status_code}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Downloaded {len(response.text):,} characters\")\n",
    "    \n",
    "    # 2. CREATE THE SOUP OBJECT\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    print(f\"\\n‚úÖ CREATED BeautifulSoup OBJECT!\")\n",
    "    print(f\"   Type: {type(soup)}\")\n",
    "    print(f\"   Parser used: html.parser\")\n",
    "    \n",
    "    # 3. Test the soup object works\n",
    "    print(f\"\\nüîç TESTING SOUP OBJECT:\")\n",
    "    \n",
    "    # Get page title\n",
    "    title = soup.title\n",
    "    print(f\"   1. Page title: {title.string if title else 'No title found'}\")\n",
    "    \n",
    "    # Count some elements\n",
    "    print(f\"   2. Element counts:\")\n",
    "    print(f\"      ‚Ä¢ <table> tags: {len(soup.find_all('table'))}\")\n",
    "    print(f\"      ‚Ä¢ <tr> tags (table rows): {len(soup.find_all('tr'))}\")\n",
    "    print(f\"      ‚Ä¢ <td> tags (table cells): {len(soup.find_all('td'))}\")\n",
    "    \n",
    "    # 4. Check if we can find programming language data\n",
    "    print(f\"\\nüîé LOOKING FOR PROGRAMMING LANGUAGE DATA:\")\n",
    "    \n",
    "    # Look for common programming languages in the text\n",
    "    languages_to_check = ['Python', 'Java', 'JavaScript', 'C++', 'C#', 'PHP', 'SQL', 'Swift', 'Go']\n",
    "    found_languages = []\n",
    "    \n",
    "    for lang in languages_to_check:\n",
    "        if lang in response.text:\n",
    "            found_languages.append(lang)\n",
    "    \n",
    "    if found_languages:\n",
    "        print(f\"   Found references to: {', '.join(found_languages)}\")\n",
    "    else:\n",
    "        print(f\"   No common programming language names found in text\")\n",
    "    \n",
    "    # 5. Show a small sample of parsed HTML\n",
    "    print(f\"\\nüìù PARSED HTML SAMPLE (first 300 characters of prettified version):\")\n",
    "    print(\"=\"*60)\n",
    "    print(soup.prettify()[:300])\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\n‚ú® Soup object is ready! You can now use it to:\")\n",
    "    print(f\"   ‚Ä¢ Find tables: soup.find_all('table')\")\n",
    "    print(f\"   ‚Ä¢ Extract data: soup.find_all('tr')\")\n",
    "    print(f\"   ‚Ä¢ Search for text: soup.find_all(text='Python')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the `Language name` and `annual average salary`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SCRAPING LANGUAGE NAMES AND ANNUAL AVERAGE SALARIES\n",
      "================================================================================\n",
      "‚úÖ Scraped 11 languages\n",
      "\n",
      "üìã EXTRACTED DATA:\n",
      " 1. No.                       ‚Üí Language\n",
      " 2. 1                         ‚Üí Python\n",
      " 3. 2                         ‚Üí Java\n",
      " 4. 3                         ‚Üí R\n",
      " 5. 4                         ‚Üí Javascript\n",
      " 6. 5                         ‚Üí Swift\n",
      " 7. 6                         ‚Üí C++\n",
      " 8. 7                         ‚Üí C#\n",
      " 9. 8                         ‚Üí PHP\n",
      "10. 9                         ‚Üí SQL\n",
      "... and 1 more\n",
      "\n",
      "üíæ Saved to: programming_languages_salaries.csv\n"
     ]
    }
   ],
   "source": [
    "#your code goes here\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SCRAPING LANGUAGE NAMES AND ANNUAL AVERAGE SALARIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find the main table\n",
    "table = soup.find('table')\n",
    "\n",
    "if table:\n",
    "    # Get all rows\n",
    "    rows = table.find_all('tr')\n",
    "    \n",
    "    # Extract data\n",
    "    languages_data = []\n",
    "    \n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) >= 2:  # We need at least language and salary\n",
    "            language = cells[0].get_text(strip=True)\n",
    "            salary = cells[1].get_text(strip=True)\n",
    "            languages_data.append([language, salary])\n",
    "    \n",
    "    print(f\"‚úÖ Scraped {len(languages_data)} languages\")\n",
    "    \n",
    "    # Display the data\n",
    "    print(f\"\\nüìã EXTRACTED DATA:\")\n",
    "    for i, (lang, salary) in enumerate(languages_data[:10], 1):  # Show first 10\n",
    "        print(f\"{i:2}. {lang:25} ‚Üí {salary}\")\n",
    "    \n",
    "    if len(languages_data) > 10:\n",
    "        print(f\"... and {len(languages_data) - 10} more\")\n",
    "    \n",
    "    # Save to CSV\n",
    "    df = pd.DataFrame(languages_data, columns=['Language', 'Average Annual Salary'])\n",
    "    df.to_csv('programming_languages_salaries.csv', index=False)\n",
    "    print(f\"\\nüíæ Saved to: programming_languages_salaries.csv\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No table found on the page\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the scrapped data into a file named *popular-languages.csv*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramesh Sannareddy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rav Ahuja\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2020-10-17  | 0.1  | Ramesh Sannareddy  |  Created initial version of the lab |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Copyright &copy; 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
